{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import nltk\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_file = open(\"data/train.json\",'r')\n",
    "\n",
    "# dev  ----> test\n",
    "dev_file = open(\"data/dev.json\",'r')\n",
    "test_file=open(\"data/test.json\",'r')\n",
    "train = json.loads(train_file.read())\n",
    "dev = json.loads(dev_file.read())\n",
    "test = json.loads(test_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# may be stem?\n",
    "\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "word_tokenizer = nltk.tokenize.regexp.WordPunctTokenizer()\n",
    "stopword =  stopwords.words()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "def doc_word_dict(doc):\n",
    "    word_dict = set()\n",
    "    for sent in doc['sentences']:\n",
    "        for word in  word_tokenizer.tokenize(sent):\n",
    "            word = lemmatize(word.lower())\n",
    "            if word not in stopword:\n",
    "                word_dict.add(word)\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_BOW(sent):\n",
    "    term_dict={}\n",
    "    for word in word_tokenizer.tokenize(sent):\n",
    "        word = lemmatize(word.lower())\n",
    "        if word not in stopword:\n",
    "            term_dict[word]=term_dict.setdefault(word,0)+1\n",
    "    return term_dict\n",
    "\n",
    "def cal_BOW(doc):\n",
    "    doc_term_matrix = [] \n",
    "    for sent in doc['sentences']:\n",
    "        temp = get_BOW(sent)\n",
    "        doc_term_matrix.append(temp)\n",
    "    return doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_doc_num2(query):\n",
    "    query =  transformer.transform(vectorizer.transform(get_BOW(query)))\n",
    "    result={}\n",
    "    for x in range(term_matrix.shape[0]):\n",
    "         result[x]=cos_distance(query.toarray(),term_matrix[x].toarray())\n",
    "            \n",
    "    minvalue=1\n",
    "    first=0\n",
    "    for item in result:\n",
    "        if minvalue > result[item]:\n",
    "            minvalue=result[item]\n",
    "            first=item     \n",
    "    del result[first]\n",
    "    \n",
    "    minvalue=1\n",
    "    second=0\n",
    "    for item in result:\n",
    "        if minvalue > result[item]:\n",
    "            minvalue=result[item]\n",
    "            second=item     \n",
    "    return first,second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting sentences from documents: 100%|██████████| 40/40 [12:45<00:00, 17.09s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.spatial.distance import cosine as cos_distance\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "transformer = TfidfTransformer(smooth_idf=False,norm=None)\n",
    "\n",
    "# store guessed question sentence no\n",
    "match_sent= [] #[[(best_match_sent_no,second_match_sent_no),...][second doc]]\n",
    "count = 0\n",
    "\n",
    "for dev_doc in tqdm(dev, desc='Extracting sentences from documents'):\n",
    "    count += 1\n",
    "    doc_match_sent = []\n",
    "    term_matrix = transformer.fit_transform(vectorizer.fit_transform(cal_BOW(dev_doc)))\n",
    "    for qa in dev_doc['qa']:\n",
    "        doc_match_sent.append(get_best_doc_num2(qa['question']))\n",
    "    match_sent.append(doc_match_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a list of set(mentioned_sent_number in the guessed )\n",
    "mentioned_sent = []\n",
    "\n",
    "for doc in match_sent:\n",
    "    tmp_doc = set()\n",
    "    for first,second in doc:\n",
    "        tmp_doc.add(first)\n",
    "        tmp_doc.add(second)\n",
    "    mentioned_sent.append(tmp_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_sent(sentence):\n",
    "    sentence = sentence.split(\".\")[0]\n",
    "    tmp = []\n",
    "    tmp += sentence.split(\",\")\n",
    "    sentence  = tmp[0].split()\n",
    "    for fraction  in tmp[1:]:\n",
    "        sentence.append(\",\")\n",
    "        sentence.extend(fraction.split())\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "st = StanfordNERTagger('/Users/ZhangJiaWei/Downloads/stanford-ner-2016-10-31/classifiers/english.muc.7class.distsim.crf.ser.gz',\n",
    "               '/Users/ZhangJiaWei/Downloads/stanford-ner-2016-10-31/stanford-ner.jar') \n",
    "# st = StanfordNERTagger('/usr/share/stanford-ner/classifiers/english.muc.7class.distsim.crf.ser.gz',\n",
    "#                '/usr/share/stanford-ner/stanford-ner.jar') \n",
    "\n",
    "# tokenize sentence\n",
    "test_tag = []\n",
    "for i in range(len(dev)):\n",
    "    test_sent_tag = []\n",
    "    for j in range(len(dev[i]['sentences'])):\n",
    "        if j in mentioned_sent[i]:# mentioned in the guess\n",
    "            test_sent_tag.append(word_tokenizer.tokenize(dev[i]['sentences'][j]))\n",
    "#             test_sent_tag.append(split_sent(dev[i]['sentences'][j]))\n",
    "        else:\n",
    "            test_sent_tag.append([])\n",
    "    test_sent_tag = st.tag_sents(test_sent_tag)\n",
    "    test_tag.append(test_sent_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn O and ORGANIZATION into other\n",
    "def tune_other(tag_list):\n",
    "    for i in range(len(tag_list)): # each document\n",
    "        for j in range(len(tag_list[i])): # each sentence\n",
    "            for k in range(len(tag_list[i][j])): # each question\n",
    "                term,tag = tag_list[i][j][k] \n",
    "                if term!='' and (tag == \"ORGANIZATION\"  or (len(term)>0 and (term,tag)!=tag_list[i][j][0] and tag == 'O' and term[0].isupper())):\n",
    "                    tag_list[i][j][k] = (term,\"OTHER\")\n",
    "\n",
    "tune_other(test_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZhangJiaWei/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "def combine_entity(tag_list):\n",
    "    for k in range(len(tag_list)):\n",
    "        for i in range(len(tag_list[k])):\n",
    "            j = 0\n",
    "            while j < len(tag_list[k][i])-2:\n",
    "                term,tag = tag_list[k][i][j]\n",
    "                term_n,tag_n = tag_list[k][i][j+1]\n",
    "                if tag == tag_n and tag != \"O\" :\n",
    "                    if term_n != \",\" and  term_n !=\"%\":\n",
    "                        temp =  (term + \" \" + term_n,tag)\n",
    "                    else:\n",
    "                        temp =  (term + term_n,tag)\n",
    "                    tag_list[k][i][j] = temp\n",
    "                    del tag_list[k][i][j+1]\n",
    "                    j -= 1\n",
    "                if term == \"-\" or term.encode('utf8') == \"\\xe2\\x80\\x93\" or term == \"\\x80\\x93\":\n",
    "                    temp =  (tag_list[k][i][j-1][0] + term + term_n,tag_list[k][i][j-1][1])\n",
    "                    tag_list[k][i][j-1] = temp\n",
    "                    del tag_list[k][i][j]\n",
    "                    del tag_list[k][i][j+1]\n",
    "                    j -= 2\n",
    "                if term == \",\" and tag_list[k][i][j-1][0].isdigit() and tag_list[k][i][j+1][0].isdigit():\n",
    "                    temp =  (tag_list[k][i][j-1][0] + term + term_n,tag_list[k][i][j-1][1])\n",
    "                    tag_list[k][i][j-1] = temp\n",
    "                    del tag_list[k][i][j]\n",
    "                    del tag_list[k][i][j+1]\n",
    "                    j -= 2\n",
    "                j += 1\n",
    "\n",
    "combine_entity(test_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn O and ORGANIZATION into other\n",
    "def tune_other_2(tag_list):\n",
    "    for i in range(len(tag_list)): # each document\n",
    "        for j in range(len(tag_list[i])): # each sentence\n",
    "            for k in range(len(tag_list[i][j])): # each question\n",
    "                term,tag = tag_list[i][j][k] \n",
    "                if \"-\" in term and tag ==\"O\":\n",
    "                    tag_list[i][j][k] = (term,\"OTHER\")\n",
    "\n",
    "tune_other_2(test_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_entity(first,second):\n",
    "    sent_tag_dict = dict.fromkeys(tags,[])\n",
    "    for k in [first,second]:\n",
    "        for j in test_tag[i][k]:\n",
    "            term,tag = j\n",
    "            if term =='':\n",
    "                continue\n",
    "            if tag == \"PERSON\" or tag == \"LOCATION\" or tag == \"OTHER\":\n",
    "                sent_tag_dict[tag] = sent_tag_dict[tag]+ [term]\n",
    "            elif tag == \"DATE\" or tag == \"TIME\" or tag == \"PERCENT\" or hasNumbers(term):\n",
    "                sent_tag_dict[\"NUMBER\"] = sent_tag_dict[\"NUMBER\"]+ [term]\n",
    "    return sent_tag_dict\n",
    "\n",
    "def remove_tag(list_tag):\n",
    "    list_tmp = []\n",
    "    for tup in list_tag:\n",
    "        term,tag = tup\n",
    "        if term != '':\n",
    "            list_tmp.append(term)\n",
    "    return list_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_list = []\n",
    "entity_pool = []\n",
    "tags = [\"PERSON\",\"LOCATION\",\"NUMBER\",\"OTHER\"]\n",
    "\n",
    "for i in range(len(match_sent)):\n",
    "    doc = dev[i]\n",
    "    sent_pool = doc['sentences']\n",
    "    test_list_tmp = []\n",
    "    entity_doc_pool = []\n",
    "    \n",
    "    for first,second in match_sent[i]:\n",
    "        tmp =  test_tag[i][first]+test_tag[i][second]\n",
    "        test_list_tmp.append(remove_tag(tmp))\n",
    "        entity_doc_pool.append(create_entity(first,second))\n",
    "\n",
    "    test_list.append(test_list_tmp)\n",
    "    entity_pool.append(entity_doc_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import operator\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def get_ranked_ans(entities_dic, question, sentence_token):\n",
    "    # identify if the entity set is empty. If True, return nothing\n",
    "    is_empty = True\n",
    "    for values in entities_dic.values():\n",
    "        if len(values) != 0:\n",
    "            is_empty = False\n",
    "            \n",
    "    if is_empty == False:\n",
    "        q_type = get_question_type(question)\n",
    "        # count the number of 'OTHER' type for analysis\n",
    "        if q_type == 'OTHER':\n",
    "            global OTHER_count \n",
    "            OTHER_count += 1\n",
    "        tmp_rank = {}\n",
    "        for ent_type,entities in entities_dic.items():\n",
    "            # answers whose content words all appear in the question should be ranked lowest.\n",
    "            for entity in entities:\n",
    "                tmp_rank[entity] = tmp_rank.setdefault(entity,0)\n",
    "                if entity in question:\n",
    "                    tmp_rank[entity] = tmp_rank.setdefault(entity,0) - 1\n",
    "            # Answers which match the question type should be ranked higher than those that don't\n",
    "            if ent_type == q_type and ent_type != 'OTHER':\n",
    "                for entity in entities:\n",
    "                    tmp_rank[entity] = tmp_rank.setdefault(entity,0) + 1\n",
    "                ######## TODO: Apply this to all types?\n",
    "            # entity closer in the sentence to a closed-class word should be preferred\n",
    "            preferred_entity = get_preferred_entity(entities, sentence_token, question)\n",
    "            if preferred_entity != None:\n",
    "                tmp_rank[preferred_entity] = tmp_rank.setdefault(preferred_entity,0) + 1\n",
    "        # sort and choose the best answer\n",
    "        sorted_ans = sorted(tmp_rank.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        \n",
    "        # log for error analysis\n",
    "        output_file.write('Q_type: ' + '\\t' + q_type + '\\n')\n",
    "        output_file.write('Ranked Answers: ' + '\\t' + str(sorted_ans).encode('utf-8') + '\\n\\n')\n",
    "        \n",
    "        # TODO: bug here. list out of index??? why?\n",
    "        if len(sorted_ans) != 0:\n",
    "            best_ans = sorted_ans[0][0]\n",
    "        else:\n",
    "            best_ans = ''\n",
    "        return best_ans\n",
    "       \n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A simple rule-based question type classifier based on key words \n",
    "\n",
    "def get_question_type(question):\n",
    "    # TODO: HAND-CODED, NEED TO BE REFINED!!\n",
    "    # TODO: need to low-case to compare?\n",
    "    \n",
    "    type_rules = [\n",
    "        ('PERSON', [\"Who\", \"who\", \"Whose\", \"whose\", \"Whom\", \"whom\"]),\n",
    "        ('LOCATION', [\"Where\", \"where\", \"area\", \"city\", \"province\", \"located\",\n",
    "                     \"location\"]),\n",
    "        ('NUMBER', [\"When\",\"when\", \"few\", \"little\", \"much\", \"many\", \"size\",\n",
    "                   \"young\", \"old\", \"long\", \"year\", \"years\", \"day\", \"era\",\n",
    "                   \"early\", \"century\", \"population\", \"cost\", \"How far\", \n",
    "                    \"how far\", \"sizes\", \"time\", \"month\", \"century\"])\n",
    "    ]\n",
    "    \n",
    "    q_type = None\n",
    "    for question_type, key_words in type_rules:\n",
    "        if q_type == None:\n",
    "            for key_word in key_words:\n",
    "                if key_word in question:\n",
    "                    q_type = question_type\n",
    "                    break\n",
    "    if q_type == None:\n",
    "        q_type = 'OTHER'\n",
    "\n",
    "    return q_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# among entities of the same type, the prefered entity should be \n",
    "# the one which is closer in the sentence to a open-class word\n",
    "# from the question.\n",
    "# ----> nouns, verbs, adjectives, and adverbs.\n",
    "\n",
    "def get_preferred_entity(entity_list, sentence_token, question):\n",
    "    preferred_entity = None\n",
    "    question_text = word_tokenize(question)\n",
    "    sentence_tag = nltk.pos_tag(sentence_token,tagset='universal')\n",
    "    question_tag = nltk.pos_tag(question_text,tagset='universal')\n",
    "    \n",
    "    # initialize a list for comparing, and set all elements as 0\n",
    "    is_open_word = [0] * len(sentence_token)\n",
    "    # find an open word in the question\n",
    "    for word, tag in question_tag:\n",
    "        if tag in ['ADJ','NOUN','VERB','ADV']:\n",
    "            # if the open word appears in the sentence, then mark as 1\n",
    "            for i in range(len(sentence_token)):\n",
    "                if sentence_token[i] == word:\n",
    "                    is_open_word[i] = 1\n",
    "    \n",
    "    # find the closest distance to an open-class word for an entity\n",
    "    def get_distance(entity):\n",
    "        # get the position of entity, and find the open class word \n",
    "        # from the nearest at both sides\n",
    "        distance = None\n",
    "        position = sentence_token.index(entity)\n",
    "        for i in range(1, len(sentence_token)):\n",
    "            if position - i >= 0:\n",
    "                if is_open_word[position - i] == 1:  # find an open-class word on the left\n",
    "                    distance = i\n",
    "                    break\n",
    "                elif position + i < len(is_open_word):  # find an open-class word on the right\n",
    "                    if is_open_word[position + i] == 1:\n",
    "                        distance = i\n",
    "                        break\n",
    "                else:\n",
    "                    distance = len(sentence_token) + 1  # didn't find open-class words\n",
    "        return distance\n",
    "    \n",
    "    # get distance for each entity and choose the best one\n",
    "    all_distance = []\n",
    "    for entity in entity_list:\n",
    "        all_distance.append(get_distance(entity))\n",
    "        preferred_entity = entity_list[all_distance.index(min(all_distance))]\n",
    "\n",
    "    return preferred_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 40/40 [02:23<00:00,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct sum: 903\n",
      "Sentence Recall: 0.716918714556\n",
      "'OTHER': 4120\n",
      "0.106699751861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "count = 1\n",
    "correct_sum = 0\n",
    "corr_sen_retr_count = 0\n",
    "OTHER_count = 0\n",
    "\n",
    "with open(\"result.txt\",'w') as output_file:\n",
    "    for i in tqdm(range(len(match_sent)), desc='Answering'):\n",
    "        for j in range(len(match_sent[i])):\n",
    "            result = get_ranked_ans(entity_pool[i][j], dev[i][\"qa\"][j]['question'], test_list[i][j])\n",
    "            output_file.write('Retrieved Entities: ' + '\\t' + str(entity_pool[i][j]) + '\\n\\n')\n",
    "#             q_id = dev[i][\"qa\"][j]['id']\n",
    "            count += 1\n",
    "            cor_answer = dev[i][\"qa\"][j]['answer']\n",
    "            Q = dev[i][\"qa\"][j]['question']\n",
    "            A_sentence = dev[i][\"sentences\"][dev[i][\"qa\"][j]['answer_sentence']]\n",
    "            sent_1, sent_2 = match_sent[i][j]\n",
    "            guessed_sentence = dev[i]['sentences'][sent_1] + ' ' + dev[i]['sentences'][sent_2]\n",
    "            \n",
    "            if result == cor_answer:\n",
    "                correct_sum += 1\n",
    "            else:\n",
    "                string1 = 'Retrieved Sentence: ' + '\\t' + guessed_sentence.encode('utf-8')+\"\\n\\n\"\n",
    "                string1_1 = '==== WRONG SENTENCES! ==== \\n' + 'Guessed_Sentence: ' + '\\t' + guessed_sentence.encode('utf-8')+\"\\n\\n\"\n",
    "                string1_2 = 'CORRECT_Sentence: ' + '\\t' + A_sentence.encode('utf-8')+\"\\n\\n\"\n",
    "                string2 = 'Q: ' + '\\t' + Q.encode('utf-8') + '\\n\\n'\n",
    "                string3 = 'CORRECT_ANSWER: ' + '\\t' + cor_answer.encode('utf-8') + '\\n'\n",
    "                string4 = 'GUESSED_ANSWER: ' + '\\t' + result.encode('utf-8')+\"\\n\"\n",
    "                \n",
    "            if A_sentence not in guessed_sentence:\n",
    "                output_file.write(string1_1)\n",
    "                output_file.write(string1_2)\n",
    "            else:\n",
    "                corr_sen_retr_count += 1\n",
    "                output_file.write(string1)\n",
    "            output_file.write(string2)\n",
    "            output_file.write('='*60 + '\\n')\n",
    "            output_file.write(string3)\n",
    "            output_file.write(string4)\n",
    "            output_file.write('='*60 + '\\n\\n')\n",
    "    print 'correct sum: ' + str(correct_sum)\n",
    "    print 'Sentence Recall: ' + str((corr_sen_retr_count+0.0)/count)\n",
    "    print \"'OTHER': \" + str(OTHER_count)\n",
    "    \n",
    "for i in dev:\n",
    "    for j in i[\"qa\"]:\n",
    "        num += 1\n",
    "print (correct_sum+0.0)/num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # run on test data\n",
    "\n",
    "# with open(\"result.txt\",'w') as output_file:\n",
    "#     output_file.write('id,answer'+'\\n')\n",
    "#     for i in tqdm(range(len(match_sent)), desc='Answering'):\n",
    "#         for j in range(len(match_sent[i])):\n",
    "#             result = get_ranked_ans(entity_pool[i][j], dev[i][\"qa\"][j]['question'], test_list[i][j])\n",
    "#             result = result.encode('utf-8')\n",
    "#             reuslt = result.replace('\" ','')\n",
    "#             result = result.replace('\"','')\n",
    "#             result = result.replace(\",\",\"-COMMA-\")\n",
    "#             q_id = dev[i][\"qa\"][j]['id']\n",
    "#             output_file.write(str(q_id) + ',' + str(result) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_1 = 'This is first sentence.'\n",
    "sent_2 = 'This is second sentence.'\n",
    "sent_3 = 'This is third sentence.'\n",
    "sentence_token = sent_1.split() + sent_2.split() + sent_3.split()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q_type:  NUMBER\n",
    "Ranked Answers:  [(u'2004', 2), (u'DialIdol', 1), (u'Howard Stern', 1), (u'2010', 1), (u'2013', 1), (u').', 0), (u'Girls', 0), (u'talked-about', 0), (u'Sanjaya Malakar', 0), (u'Worst', -2), (u'Vote', -3)]\n",
    "\n",
    "Retrieved Entities:  {'PERSON': [u'Sanjaya Malakar', u'Howard Stern'], 'OTHER': [u'DialIdol', u'Vote', u'Worst', u'Vote', u'Girls', u').', u'talked-about', u'Vote', u'Worst'], 'LOCATION': [], 'NUMBER': [u'2004', u'2013', u'2010']}\n",
    "\n",
    "Retrieved Sentence:  Since 2004, votes also have been affected to a limited degree by online communities such as DialIdol, Vote for the Worst (closed in 2013), and Vote for the Girls (started 2010). Teenager Sanjaya Malakar was the season's most talked-about contestant for his unusual hairdo, and for managing to survive elimination for many weeks due in part to the weblog Vote for the Worst and satellite radio personality Howard Stern, who both encouraged fans to vote for him.\n",
    "\n",
    "Q:  What year did Vote for the Worst cease operations? \n",
    "\n",
    "============================================================\n",
    "CORRECT_ANSWER:  2013\n",
    "GUESSED_ANSWER:  2004\n",
    "============================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
